import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from io import BytesIO
from datetime import datetime
from PIL import Image, ImageFilter
import hashlib
import nltk
from nltk.sentiment import SentimentIntensityAnalyzer
import requests  # â† æ–°å¢ï¼Œç”¨äº NewsAPI

# -----------------------
# åˆå§‹åŒ–æƒ…æ„Ÿåˆ†æå™¨
# -----------------------
@st.cache_resource(show_spinner=False)
def load_vader():
    try:
        nltk.data.find('sentiment/vader_lexicon')
    except LookupError:
        nltk.download('vader_lexicon')
    return SentimentIntensityAnalyzer()

sia = load_vader()

st.set_page_config(page_title="æƒ…ç»ªæ˜Ÿç©º Emotional Constellation", page_icon="âœ¨", layout="wide")
st.title("ğŸŒŒ æƒ…ç»ªæ˜Ÿç©º (Emotional Constellation)")
st.caption("å°†æ–‡æœ¬æƒ…ç»ªæ˜ å°„ä¸ºåŠ¨æ€æ˜Ÿç©ºï¼šé¢œè‰²=æƒ…ç»ªç±»åˆ«ï¼Œäº®åº¦/å¤§å°=æƒ…ç»ªå¼ºåº¦ã€‚Data â†’ Art â†’ Interaction.")

# -----------------------
# ğŸ“° ä» NewsAPI æŠ“å–æ–°é—»
# -----------------------
def fetch_news(api_key, keyword="technology", page_size=30):
    """Fetch latest English news articles containing the keyword."""
    url = "https://newsapi.org/v2/everything"
    params = {
        "q": keyword,
        "language": "en",
        "sortBy": "publishedAt",
        "pageSize": page_size,
        "apiKey": api_key,
    }
    try:
        resp = requests.get(url, params=params, timeout=10)
        data = resp.json()
        if data.get("status") != "ok":
            st.warning("NewsAPI è¿”å›é”™è¯¯: " + str(data.get("message")))
            return pd.DataFrame()
        articles = data.get("articles", [])
        df = pd.DataFrame([{
            "timestamp": a["publishedAt"][:10],
            "text": a["title"] + " - " + (a["description"] or ""),
            "source": a["source"]["name"]
        } for a in articles])
        return df
    except Exception as e:
        st.error(f"è¯·æ±‚ NewsAPI æ—¶å‡ºé”™: {e}")
        return pd.DataFrame()

# -----------------------
# å‡½æ•°å®šä¹‰
# -----------------------
def analyze_sentiment(text: str) -> dict:
    if not isinstance(text, str) or not text.strip():
        return {"neg": 0.0, "neu": 1.0, "pos": 0.0, "compound": 0.0}
    scores = sia.polarity_scores(text)
    return scores

def classify_emotion(compound: float) -> str:
    if compound >= 0.05:
        return "positive"
    elif compound <= -0.05:
        return "negative"
    else:
        return "neutral"

def seed_from_text(text: str) -> int:
    h = hashlib.sha1(text.encode("utf-8", errors="ignore")).hexdigest()
    return int(h[:8], 16)

def create_constellation(df: pd.DataFrame, width=1600, height=900, glow=True):
    fig, ax = plt.subplots(figsize=(width/100, height/100), dpi=100)
    ax.set_facecolor("black")
    ax.set_xlim(0, 1)
    ax.set_ylim(0, 1)
    ax.axis("off")

    color_map = {
        "positive": (1.0, 0.93, 0.2),
        "neutral": (0.8, 0.8, 0.9),
        "negative": (0.3, 0.55, 1.0),
    }

    xs, ys, ss, cs, alphas = [], [], [], [], []
    for _, row in df.iterrows():
        text = str(row.get("text", ""))
        comp = float(row.get("compound", 0))
        emo = row.get("emotion", "neutral")

        rng = np.random.default_rng(seed_from_text(text))
        x = rng.uniform(0.02, 0.98)
        y = rng.uniform(0.06, 0.94)
        intensity = min(1.0, max(0.0, abs(comp)))
        size = 20 + 180 * intensity**0.8
        alpha = 0.25 + 0.65 * intensity

        xs.append(x); ys.append(y); ss.append(size); alphas.append(alpha)
        cs.append(color_map.get(emo, (0.9, 0.9, 0.9)))

    if xs:
        ax.scatter(xs, ys, s=[s*3.0 for s in ss], c=cs, alpha=[a*0.18 for a in alphas], linewidths=0, marker="o")
        ax.scatter(xs, ys, s=ss, c=cs, alpha=alphas, linewidths=0, marker="o")

    if len(xs) >= 6:
        pts = np.column_stack([xs, ys])
        for i in range(len(pts)):
            d = np.sum((pts - pts[i])**2, axis=1)
            nn = np.argsort(d)[1:3]
            for j in nn:
                ax.plot([pts[i,0], pts[j,0]], [pts[i,1], pts[j,1]], linewidth=0.3, alpha=0.15, c="white")

    buf = BytesIO()
    plt.tight_layout(pad=0)
    plt.savefig(buf, format="png", facecolor=fig.get_facecolor(), bbox_inches="tight", pad_inches=0)
    plt.close(fig)
    buf.seek(0)

    if glow:
        im = Image.open(buf).convert("RGBA")
        blurred = im.filter(ImageFilter.GaussianBlur(radius=1.2))
        out = Image.alpha_composite(blurred, im)
        out_buf = BytesIO()
        out.save(out_buf, format="PNG")
        out_buf.seek(0)
        return out_buf
    else:
        return buf

# -----------------------
# ç•Œé¢ä¸äº¤äº’
# -----------------------
with st.expander("â„¹ï¸ ä½¿ç”¨è¯´æ˜ / How to use", expanded=False):
    st.markdown("""
    1. é€‰æ‹© **æ•°æ®è¾“å…¥æ–¹å¼**ï¼ˆä¸Šä¼  CSV / ç²˜è´´æ–‡æœ¬ / æŠ“å–æ–°é—»ï¼‰ã€‚  
    2. ç‚¹å‡» **åˆ†ææƒ…ç»ª**ï¼Œå¾—åˆ°æ¯æ¡æ–‡æœ¬çš„ææ€§åˆ†å€¼ã€‚  
    3. ä½¿ç”¨å·¦ä¾§è¿‡æ»¤å™¨é€‰æ‹©æƒ…ç»ªç±»å‹æˆ–æ—¶é—´èŒƒå›´ï¼ŒæŸ¥çœ‹ç”Ÿæˆçš„â€œæƒ…ç»ªæ˜Ÿç©ºâ€ã€‚  
    4. ç‚¹å‡» **å¯¼å‡ºå›¾åƒ** ä¿å­˜å½“å‰æ˜Ÿç©ºä¸º PNGã€‚
    """)

st.sidebar.header("è¿‡æ»¤ / Filters")
emotion_options = ["positive", "neutral", "negative"]
selected_emotions = st.sidebar.multiselect("æƒ…ç»ªç±»å‹ / Emotion types", options=emotion_options, default=emotion_options)
st.sidebar.markdown("---")
st.sidebar.header("æ•°æ®è¾“å…¥ / Data input")

input_mode = st.sidebar.radio("é€‰æ‹©æ•°æ®æ¥æº", ["ä¸Šä¼  CSV", "ç²˜è´´æ–‡æœ¬", "æŠ“å–æ–°é—»"], index=0)
df = pd.DataFrame()

if input_mode == "ä¸Šä¼  CSV":
    up = st.sidebar.file_uploader("ä¸Šä¼  CSV (åŒ…å« text åˆ—)", type=["csv"])
    if up is not None:
        try:
            df = pd.read_csv(up)
        except Exception:
            st.sidebar.error("æ— æ³•è¯»å–è¯¥ CSVï¼Œè¯·ç¡®è®¤ç¼–ç ä¸åˆ†éš”ç¬¦ã€‚")

elif input_mode == "ç²˜è´´æ–‡æœ¬":
    user_text = st.sidebar.text_area("ç²˜è´´å¤šè¡Œæ–‡æœ¬ï¼ˆæ¯è¡Œä¸€æ¡è®°å½•ï¼‰", height=200)
    if st.sidebar.button("æ·»åŠ åˆ°æ•°æ®é›†", use_container_width=True):
        rows = [t for t in user_text.splitlines() if t.strip()]
        df = pd.DataFrame({"text": rows})
        df["timestamp"] = pd.Timestamp.today().date().astype(str)

elif input_mode == "æŠ“å–æ–°é—»":
    keyword = st.sidebar.text_input("è¾“å…¥å…³é”®è¯ï¼ˆè‹±æ–‡ï¼Œå¦‚ technology / economy / happinessï¼‰", "technology")
    if st.sidebar.button("ä» NewsAPI æŠ“å–æ–°é—»", use_container_width=True):
        api_key = st.secrets.get("NEWS_API_KEY", "")
        if not api_key:
            st.sidebar.error("âš ï¸ æœªæ£€æµ‹åˆ° API Keyï¼Œè¯·åœ¨ Streamlit Secrets ä¸­æ·»åŠ  NEWS_API_KEY")
        else:
            df = fetch_news(api_key, keyword=keyword)

if df.empty:
    try:
        df = pd.read_csv("sample_data.csv")
        st.info("æœªæä¾›æ•°æ®ï¼Œä½¿ç”¨ç¤ºä¾‹æ•°æ® sample_data.csvã€‚")
    except Exception:
        st.error("æœªèƒ½åŠ è½½ç¤ºä¾‹æ•°æ®ã€‚")
        st.stop()

if "text" not in df.columns:
    st.error("æ•°æ®ä¸­å¿…é¡»åŒ…å« `text` åˆ—ã€‚")
    st.stop()

with st.spinner("åˆ†ææƒ…ç»ªä¸­..."):
    sentiments = df["text"].fillna("").apply(analyze_sentiment).apply(pd.Series)
    df = pd.concat([df.reset_index(drop=True), sentiments.reset_index(drop=True)], axis=1)
    df["emotion"] = df["compound"].apply(classify_emotion)

df = df[df["emotion"].isin(selected_emotions)].reset_index(drop=True)

left, right = st.columns([0.58, 0.42])
with left:
    st.subheader("â­ æƒ…ç»ªæ˜Ÿç©º / Constellation")
    if df.empty:
        st.warning("å½“å‰è¿‡æ»¤æ¡ä»¶ä¸‹æ²¡æœ‰æ•°æ®ç‚¹ã€‚")
    else:
        img_buf = create_constellation(df, width=1600, height=900, glow=True)
        st.image(img_buf, caption="Emotional Constellation", use_column_width=True)
        st.download_button("ğŸ’¾ å¯¼å‡ºå½“å‰æ˜Ÿç©ºä¸º PNG", data=img_buf, file_name="emotional_constellation.png", mime="image/png")

with right:
    st.subheader("ğŸ“Š æ•°æ®ä¸æƒ…ç»ª / Data & Sentiment")
    st.dataframe(df[["text", "compound", "pos", "neu", "neg", "emotion"] + ([c for c in ["timestamp","source"] if c in df.columns])],
                 use_container_width=True, height=420)

st.markdown("---")
st.caption("Made with â¤ï¸  Data â†’ Sentiment â†’ Generative Art â†’ Streamlit.  Â© 2025")
